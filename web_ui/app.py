import streamlit as st
import os

# =================  æ ¸å¿ƒ 1: æ˜¾å­˜ç‰©ç†éš”ç¦» =================
# å¿…é¡»åœ¨å¯¼å…¥ torch/core ä¹‹å‰è®¾ç½®ï¼
# è¿™è®© Python è¿›ç¨‹èƒ½çœ‹åˆ°æ‰€æœ‰å¡ï¼Œå…·ä½“çš„éš”ç¦»ç”± core å†…éƒ¨çš„ç±»è‡ªå·±ç®¡ç†ï¼š
# - RetrievalSystem -> å¼ºåˆ¶ç”¨ cuda:0
# - VLLMEngine -> å¼ºåˆ¶ç”¨ cuda:1, cuda:2
os.environ["CUDA_VISIBLE_DEVICES"] = "0,1,2"

# å¯¼å…¥ UI ç»„ä»¶
from PIL import Image

# å¯¼å…¥æ–°æ ¸å¿ƒ (æ³¨æ„ï¼šè¿™é‡Œä¸éœ€è¦ vectordb.py äº†ï¼Œç›´æ¥è°ƒ core)
from core.retrieval import RetrievalSystem
from core.llm_engine import VLLMEngine

# --- 1. é¡µé¢åŸºç¡€é…ç½® ---
st.set_page_config(layout="wide", page_title="DualSight-RAG", page_icon="ğŸ‘ï¸")

st.markdown("""
<style>
    .stChatFloatingInputContainer {bottom: 20px;}
    .evidence-card {
        background-color: #f0f2f6; border-radius: 8px; padding: 10px; margin-bottom: 5px;
        border-left: 4px solid #00E676; font-size: 0.9em;
    }
    .score-tag {
        background-color: #e3f2fd; padding: 2px 6px; border-radius: 4px; font-size: 0.8em; color: #1565c0;
    }
</style>
""", unsafe_allow_html=True)

# --- 2. æ ¸å¿ƒèµ„æºåŠ è½½ (å•ä¾‹æ¨¡å¼) ---
@st.cache_resource
def load_system():
    """
    åˆå§‹åŒ–ä¸¤å¤§å¼•æ“ï¼Œåˆ©ç”¨ Streamlit ç¼“å­˜æœºåˆ¶ä¿è¯åªåŠ è½½ä¸€æ¬¡
    """
    # A. åˆå§‹åŒ–æ£€ç´¢ç³»ç»Ÿ (GPU 0)
    # è·¯å¾„æ ¹æ®ä½ ä¹‹å‰çš„è®¾ç½®ï¼Œå‡è®¾åœ¨ vectorstore/energy ä¸‹
    retriever = RetrievalSystem(
        index_root_path="vectorstore/energy",
        doc_store_path="vectorstore/energy/doc_store.json"
    )
    
    # B. åˆå§‹åŒ–ç”Ÿæˆå¼•æ“ (GPU 1 & 2)
    llm = VLLMEngine() 
    
    return retriever, llm

# åŠ è½½ç³»ç»Ÿ (å¸¦æœ‰åŠ è½½åŠ¨ç”»)
if "system_loaded" not in st.session_state:
    with st.spinner("ğŸš€ Booting up DualSight System (SigLIP + Chunked BGE + vLLM)..."):
        try:
            retriever, llm = load_system()
            st.session_state.retriever = retriever
            st.session_state.llm = llm
            st.session_state.system_loaded = True
            st.success("âœ… System Online: GPU 0 (Search) + GPU 1&2 (Reasoning)")
        except Exception as e:
            st.error(f"âŒ System Init Failed: {e}")
            st.stop()
else:
    retriever = st.session_state.retriever
    llm = st.session_state.llm

# --- 3. ä¾§è¾¹æ  ---
with st.sidebar:
    st.title("ğŸ‘ï¸ DualSight-RAG")
    st.caption("Unified-Space Multimodal RAG")
    st.markdown("---")

    # ğŸ–¼ï¸ å¤šæ¨¡æ€è¾“å…¥
    st.header("ğŸ–¼ï¸ Multimodal Input")
    uploaded_file = st.file_uploader("Upload query image (optional):", type=["png", "jpg", "jpeg"])
    
    user_image_path = None
    if uploaded_file:
        # ä¿å­˜ä¸Šä¼ çš„å›¾ç‰‡åˆ°ä¸´æ—¶ç›®å½•ï¼Œä»¥ä¾¿åç»­å¤„ç†ï¼ˆå¦‚æœéœ€è¦ï¼‰
        # ç›®å‰ vLLM ç­–ç•¥åªå¤„ç†æ–‡æœ¬ï¼Œè¿™é‡Œä»…åšå±•ç¤º
        st.image(uploaded_file, caption="Query Image", use_column_width=True)
        st.success("Image added to context!")

    st.markdown("---")
    
    # âš™ï¸ å‚æ•°
    st.header("âš™ï¸ Rerank Settings")
    top_k = st.slider("Top-K Evidence", 1, 10, 5)
    
    if st.button("ğŸ§¹ Clear Chat"):
        st.session_state.messages = []
        st.rerun()

# --- 4. ä¸»èŠå¤©é€»è¾‘ ---
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "Hello! I'm ready to analyze energy documents using Dual-Path retrieval."}
    ]

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

if prompt := st.chat_input("Ask about Greenmount Road..."):
    # 1. æ˜¾ç¤ºç”¨æˆ·æé—®
    st.chat_message("user").write(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("assistant"):
        evidence_text = ""
        debug_info = st.empty()
        
        # --- æ ¸å¿ƒ 2: æ£€ç´¢é˜¶æ®µ (åŒè·¯å¬å› + åˆ†å—èšåˆé‡æ’) ---
        with st.status("ğŸ” Dual-Path Retrieval & Reranking...", expanded=True) as status:
            # A. æ£€ç´¢
            # search_and_rerank å†…éƒ¨å·²ç»åŒ…å«äº† SigLIP å¬å› -> BGE åˆ†å—æ‰“åˆ†
            results = retriever.search_and_rerank(prompt, top_k_final=top_k)
            
            if results:
                status.write(f"âœ… Found {len(results)} relevant docs (after Reranking).")
                
                # B. å±•ç¤ºè¯æ®å¡ç‰‡ (Evidence Cards)
                cols = st.columns(min(len(results), 3))
                for i, res in enumerate(results):
                    score = res.get('score', 0.0)
                    
                    # æ‹¼æ¥ Contextï¼šåŒ…å« Qwen é¢„ç”Ÿæˆçš„è¯¦ç»†æè¿°
                    evidence_text += f"\n[Document {i+1} (Score: {score:.4f})]:\n{res['content']}\n"
                    
                    # åœ¨ç•Œé¢æ˜¾ç¤ºç¼©ç•¥å›¾
                    if i < 3: 
                        with cols[i]:
                            st.image(res['path'], caption=f"Rank {i+1} (Score: {score:.2f})")
                            with st.expander(f"See Description {i+1}"):
                                st.caption(res['content'][:200] + "...")
            else:
                status.write("âš ï¸ No relevant documents found.")
            
            status.update(label="Retrieval Complete", state="complete")

        # --- æ ¸å¿ƒ 3: ç”Ÿæˆé˜¶æ®µ (vLLM åŠ é€Ÿ) ---
        response_placeholder = st.empty()
        
        # æ„é€  Promptï¼šåªå–‚ Retrieve åˆ°çš„ Text Context
        # ç†ç”±ï¼šQwen é¢„å¤„ç†çš„æè¿°å·²ç»æ˜¯ OCR çº§åˆ«çš„äº†ï¼Œç›´æ¥å–‚æ–‡æœ¬ç»™ vLLM 
        # æ—¢èƒ½é¿å… vLLM å¤šæ¨¡æ€æ ¼å¼çš„å‘ï¼Œåˆèƒ½æå¤§æå‡æ¨ç†é€Ÿåº¦ (Text-Only æ˜¯æœ€å¿«çš„)
        final_prompt = f"""
        Reference Context (High-Fidelity OCR Descriptions):
        {evidence_text if evidence_text else "No specific context found."}
        
        User Question: "{prompt}"
        
        Please answer the User Question accurately based ONLY on the Reference Context above.
        If the answer involves data from tables/charts, cite the Document number.
        """
        
        # è°ƒç”¨ vLLM
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ç§»é™¤äº† images å‚æ•°ï¼Œå› ä¸º context å·²ç»åŒ…å«äº†å›¾ç‰‡ä¿¡æ¯
        full_response = llm.generate(
            prompt=final_prompt,
            system_prompt="You are an expert AI assistant. Answer strictly based on the provided context."
        )
        
        response_placeholder.markdown(full_response)
        st.session_state.messages.append({"role": "assistant", "content": full_response})