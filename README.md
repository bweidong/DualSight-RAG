# ğŸ‘ï¸ DualSight-RAG

<div align="center">

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![vLLM](https://img.shields.io/badge/Inference-vLLM-green)
![Qwen](https://img.shields.io/badge/Model-Qwen2.5--VL--32-purple)
![SigLIP](https://img.shields.io/badge/Retrieval-SigLIP-6f42c1)
![License](https://img.shields.io/badge/License-Apache--2.0-orange)

**Full-Stack SigLIP Multimodal RAG with Fragment-First Retrieval & Score Aggregation.**

[Key Features](#-key-features) â€¢ [Architecture](#-architecture) â€¢ [Quick Start](#-quick-start) â€¢ [Performance](#-performance) â€¢ [Project Structure](#-project-structure) â€¢ [License](#-license)


</div>

---

## ğŸ“– Introduction

**DualSight-RAG** is a high-performance **multimodal RAG** system designed for dense, detail-sensitive retrieval (e.g., charts, technical docs, long reports).

Instead of indexing whole documents, DualSight adopts a **Fragment-First** strategy:

- **Index fragments (chunks)** rather than entire documents
- Retrieve **Top-N fragments**, then **aggregate** them into document-level scores
- Use **SigLIP** as a *unified encoder* for both **text** and **image**, avoiding heavy cross-encoder rerankers while maintaining strong recall

**Pipeline**  
**Query â†’ Fragment Retrieval (Top-N) â†’ Group-by DocID â†’ Score Aggregation â†’ Dual-Path Fusion â†’ Multimodal LLM Generation**

---

## ğŸ¬ Demo



<p align="center">
  <img src="assets/demo.gif" width="900" alt="DualSight-RAG demo"/>
</p>

---

## ğŸš€ Key Features

### 1) âš¡ Unified SigLIP Retrieval (Text + Image)

A single encoder handles both modalities:

- **Visual path:** text-to-image retrieval in a shared embedding space  
- **Text path:** text-to-text fragment retrieval via dense similarity  
- **Unified space:** no projection / adapter layers required

### 2) ğŸ§© Fragment-First Retrieval + Aggregation

To mitigate **lost-in-the-middle** behavior and better cover long documents:

- **Ingestion:** slice long text into overlapping **fragments** before indexing
- **Retrieval:** retrieve **Top-N fragments** (instead of Top-K documents)
- **Aggregation:** group fragments by `doc_id` and compute a document score

**Default aggregation (peak + coverage):**

\[
s(d)=\max_{i \in \mathcal{F}(d)} s_i \;+\; \frac{1}{K}\sum_{i \in \text{TopK}(\mathcal{F}(d))} s_i
\]

- \( \mathcal{F}(d) \): retrieved fragments belonging to document \(d\)  
- \( s_i \): similarity score for fragment \(i\)  
- `TopK`: top-K fragments within the same document

### 3) âš–ï¸ Weighted Dual-Path Fusion

Final ranking combines **visual** and **text** evidence:

\[
S(d)=\alpha \cdot S_{\text{visual}}(d) + (1-\alpha)\cdot S_{\text{text}}(d)
\]

This helps retrieve chart-heavy pages even when OCR/text is noisy, and vice versa.

### 4) ğŸš€ Hardware-Isolated Inference (Optional)

Recommended deployment for stable throughput:

- **GPU 0:** SigLIP (embedding + retrieval)
- **GPU 1â€“2:** vLLM multimodal generation (tensor parallel)

This prevents retrieval latency from blocking generation.
---

## ğŸ› ï¸ Architecture

<p align="center">
  <a href="assets/Architecture.jpg">
    <img src="assets/Architecture.jpg" width="900" alt="DualSight-RAG architecture"/>
  </a>
</p>

---

## ğŸ“‚ Project Structure

```text
DualSight-RAG/
â”œâ”€â”€ assets/
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.py           # Model paths and runtime settings
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ retrieval.py        # Fragment search, group-by, aggregation, fusion
â”‚   â””â”€â”€ llm_engine.py       # vLLM inference wrapper (optional)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ ingest.py           # Chunking -> SigLIP encoding -> FAISS build
â”‚   â””â”€â”€ evaluate.py         # Recall/MRR evaluation
â”œâ”€â”€ web_ui/
â”‚   â””â”€â”€ app.py              # Streamlit UI (scores + retrieval breakdown)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“¦ Quick Start

### 1) Prerequisites

- Python 3.10+
- GPU recommended (SigLIP + VLM)
- RAM: 64GB+ recommended for larger FAISS indices

### 2) Install

```bash
pip install -r requirements.txt
```

### 3) Configure (`configs/config.py`)

```python
MODEL_PATHS = {
    "vlm":   "/path/to/your_multimodal_llm",
    "siglip": "/path/to/siglip-so400m-patch14-384"
}

RETRIEVAL = {
    "top_n_fragments": 100,
    "top_k_context": 5,
    "agg_topk": 5,
    "alpha_fusion": 0.5
}
```

### 4) Build Fragment Index

This generates FAISS indices and the fragment-to-document mapping:

```bash
python scripts/ingest.py --dataset energy
```

### 5) Run Demo UI

```bash
streamlit run web_ui/app.py
```

---

## ğŸ“Š Performance

Results on a vertical-domain dataset (complex charts/tables/text).  
**All numbers are consistent with the resume version of this project.**

| Category | Metric | Result | What it reflects |
|---|---|---:|---|
| Retrieval quality | Recall@5 | **42.33% â†’ 85.9%** | Dual-index retrieval + chunked aggregation rerank |
| Ranking quality | MRR@50 | **+0.16** | Improvement vs. baseline pipeline |
| End-to-end | F1 | **+0.14** | Improvement vs. baseline with vLLM (TP=2) deployment |
| Context | Evidence size | **Top-5** | Final context selected after reranking + aggregation |

> Note: Exact dataset details and baseline configuration can be provided in `scripts/eval.py` (sanitized if needed).


---

## ğŸ“ To-Do

- [x] Unified SigLIP dual-path retrieval
- [x] Fragment indexing + group-by aggregation
- [x] Mathematical score aggregation
- [ ] Adaptive `alpha` based on query type/length
- [ ] On-the-fly PDF chunking & indexing

---

## ğŸ¤ Contributing

Issues and PRs are welcome.  
Please include minimal repro steps and environment info.

---

## ğŸ“„ License

Apache-2.0

